% Build on the outline below.  Cite by using \citep{Author2016} to add a
% parenthetical citation; use \citet{Author2016} to get a textual cite like
% this: Author (2016). 

Replication crisis

LaCour scandal

p-Hacking.  check out special issue on p-hacking: \url{http://www.tandfonline.com/toc/hcms20/9/4}

malpractice not always so blatent or intentional: confirmation bias, garden of forking paths (see \url{http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf})

Introduce \citet{Newman2015}, perhaps noting the press attention it has received (e.g., \url{http://www.psmag.com/health-and-behavior/five-studies-bernie-sanders-says-the-rich-are-deranged})

Data Access and Research Transparency (DA-RT): A Joint Statement by Political Science Journal Editors: \url{http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=9911378&fulltextType=LT&fileId=S2049847015000448}

Leek and Peng, ``Reproducible Research Can Still Be Wrong: Adopting a Prevention Approach" \url{http://arxiv.org/abs/1502.03169}: ``Unfortunately, the mere reproducibility of computational results is insufficient to address the replication crisis because even a reproducible analysis can suffer from many problems—confounding from omitted variables, poor study design, missing data—that threaten the validity and useful interpretation of the results. While improving the reproducibility of research may increase the rate at which flawed analyses are uncovered, as recent high-profile examples have demonstrated, it does not change the fact that problematic research is conducted in the first place.'' (p1)

Sound research is a cornerstone of the advancement of knowledge across all fields of study. The need for carefully conducted, replicable empirical research is not a new concern, though it has gained additional attention of late. The rise of p-hacking, the practice of manipulating data and methodological approaches in the aim of generating statistically significant results, fuels this growing concern. Recent instances highlight the growing concern. Uncovered by the \citet{OpenScienceCollaboration2015}, the replication crisis highlights the severity of the problem. Of 100 published studies that the authors attempted to replicate, just 36 produced the same results as those cited in the published articles \citep{OpenScienceCollaboration2015}. Additionally cases such as that of Michael LaCour, the UCLA graduate student who fabricated data, provide further proof of the need for vigilance in combatting academic fraud and malpractice. Given the pressure to produce publishable work, careful consideration of how to detect and minimize academic fraud, along with processes to avoid engaging in questionable research practices are of the utmost importance.

It is important to note that academic misconduct and faulty research need not be the product of an intentional attempt to dupe the system. Confirmation bias, a well-documented tendency to accept those pieces of evidence that confirm our pre-existing beliefs while discounting evidence that counters them undoubtedly can contribute to questionable research practices. Results that support a carefully crafted theory may be accepted as robust, even without thorough examination, while those results that disconfirm the same theory may be dismissed as misspecification. Even the process of developing a model aimed at testing a theory might contribute to faulty research. \citet{Gelman2013garden} analogy of a garden of forking paths suggests that even when researchers are not actively engaged in fishing for results, decisions that are made about how to carry out the research necessarily preclude other comparisons from being considered. These decisions, if not carefully considered, can lead to unintended malpractice.

Our aim in this paper is to provide a guide to avoiding academic malpractice through a series of steps, that if followed, are sure to produce sound results that are replicable and transparent, a goal that if accepted widely across academia, could minimize the occurrence of academic fraud and halt the replication crisis in its tracks. In order to demonstrate the importance of these steps, and how issues can arise when they are ignored, we utilize a recently published article, “False Consciousness or Class Awareness? Local Income Inequality, Personal Economic Position, and Belief in American Meritocracy” by \citet{Newman2015}.

This article, published in the American Journal of Political Science examines the effect of local inequality on individual’s belief in the meritocratic nature of America. The findings suggest that rich and poor respond differently to local inequality, with the rich being no less likely to reject meritocracy when inequality is high, while higher inequality increases the likelihood the poor will reject meritocracy. Seen as providing further evidence of the growing gulf between the rich and poor, not just in terms of economic resources, but in their perceptions of the system they cohabitate, the results have gained media attention beyond the field of political science, being featured in an article in Pacific Standard which summarizes a growing body of evidence documenting the widening psychological gap between the rich and poor.

However, the article's empirical results are misinterpreted, and efforts to replicate its analyses reveal additional problems.  As a result, its sanguine conclusions regarding the prospects for redistribution are unsupported. As a result, \citet{Newman2015} provides a cautionary tale that highlights seven steps that can help researchers to avoid committing academic malpractice, both of the unintentional and intentional sort. Below we outline each of these seven steps, ranging from ensuring that results are replicable, to exercising care in coding and imputing missing values, to properly interpreting interactice effects. We rely on \citet{Newman2015} to provide illustrations of the dangers that can arise when researchers fail to adhere to these simple processes in the hopes that the mistakes made by its authors might help prevent others from falling into similar situations.



% How does the context of income inequality affect political and economic attitudes?  Many studies have found that greater inequality tends to be associated with attitudes that reinforce rather than challenge the status quo. \citet{Newman2015}, however, argue that inequality instead activates disillusionment with the dominant U.S. ideology, leading poorer individuals in local contexts of higher inequality to become more class conscious and to reject meritocracy.  However, the article's empirical results are misinterpreted, and efforts to replicate its analyses reveal additional problems.  As a result, its sanguine conclusions regarding the prospects for redistribution are unsupported.
