% Build on the outline below.  Cite by using \citep{Author2016} to add a
% parenthetical citation; use \citet{Author2016} to get a textual cite like
% this: Author (2016). 


\section{Wrangle Data with Care}
Bigger, and better. In survey studies, When conducting quantitative analysis, Scholars look forwards to have a sample with large-N to test more variables and their relationships in statistical models. However, it is difficult to ensure the quality of all surveys in reality: they can be underrepresentative of some specific populations because of  non-responses or biased questionarie design, or the sample size is too small due to the resource limit of survey institutes. In order to solve this problem, scholars usually combine different surveys projects or several waves of the same survey together to accquire a satisfising size of sample. 

Although it is a common practice, there are several important issues should be noted here. In general, after merging multiple data, scholars should scrutinize whether the numbers of the same variable in different data are identical or not. Second, scholars should be always cautious about the consistency and accuracy of the variable measured in different surveys. This requires cautions to both the questions and the measures of variables.In the ideal situation, the format, wording and measure of questions with regards to the specific variable of interests should be the same across different surveys. If scholars are comfortable with questions of the specific variable are asked differently, they will still need to defense the combination of these questions with evidence that they are actually asking the same thing and will not differentiate survey takers' opinion dramatically. Many empirical studies show that even minor changes in question languages can vary respondents'answer becasue of their different cognition and reception of the information \citep{Bishop1978, Rasinski1989, Zaller1992, Bertrand2001}.  For example, changing a statement from "climate change" to "global warming", respondents' agreement sharply drops by 26.2\% \citep{Schuldt2011}. Furthermore, scholars should also need to be very careful in maintaining the measurement consistency in coding and recoding processes. This means scholars should not only unify the measures for the specific variables of interests in different surveys, but also ensure the measures they choose to adopt are accordant with the common practices in the field to ensure comparability with other studies, unless there are specific reasons to use a different measure. 


These issues can be easier said than done. The example article used in this paper clearly show that even experienced scholars can fall on these simple issues. First of all, some data do not match with each other after merging the four surveys. When we draw the data out from the countries analyzed in Table 1 and Table 2 \citep{Newman2015}, it is obvious that the Bush share of the vote in the 2004 election are not exactly match with each other: among all the counties examined in both tables, only fewer than 10\% have matching data (even when rounded to two decimal places). 

\input{../figures/05_wrangle_with_care_bush_al}

Second, the authors have some unreasonable practices in their paper with regards to variable measures in the coding process. For example, they use a 5-point scale measure for respondent's party identification instead of the the standard 7-point scale party identification is widely applied in classic American politics. According to this measure, 5 and 1 represent strong partisanship , 4 and 2 represent weak partisanship, and 3 represents independent party identification. However, the questions asked in the Pew survey reveals more about the party inclination of indpendent voters. The survey firstly asks whether respondents identify their own party, and how strong such identification is. If respondents identify themselves as indpendent, the survey continue to ask which party they lean to. These questions provide more information about independent voters' party incliation, and we cannot find any reason to throw away this information in this study by adopting the 5-point scale partisanship measure. Besides, the measure of unemployment used in the paper is also problematic. In the 2006 Pew Immigration Poll, unemployment is measured by two questions: (1) whether you are working (either full-time or part-time employed) or not, and (2) if you are not working, which is your current status (student, homeaker, retired, or unemployed). However, in the 2005 Pew News Interest Index Poll, 2007 and 2009 Pew Values Survey, only the first question was asked, and the authors treat respondents in the combined dataset who are not working as "unemployed", ignoring the detailed employment status difference of the 2,000 respondents of the 2006 survey.

These malpractices seems small, but they may dramatically change the result of statistical model when inputting wrong data and severely undermine the validity of the study. To prevent these problems, every scholar to be more scrutinized in merging data. They need to review all the questions and variables before merging, reassure the measures of variables across dataset are consistent and valid in the recoding process, and they need to be more transparent in data coding. 



